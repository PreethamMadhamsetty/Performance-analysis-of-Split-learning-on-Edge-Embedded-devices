{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cdea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "users = 1 # number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f23966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b05b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:0\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0940b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov  1 14:23:31 2018\n",
    "@author: tshzzz\n",
    "\"\"\"\n",
    "\n",
    "def conv_dw_server(inplane,outplane,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,outplane,kernel_size = 1,groups = 1,stride=1),\n",
    "        nn.BatchNorm2d(outplane),\n",
    "        nn.ReLU()    \n",
    "        )\n",
    "\n",
    "def conv_dw(inplane,outplane,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,inplane,kernel_size = 3,groups = inplane,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(inplane),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(inplane,outplane,kernel_size = 1,groups = 1,stride=1),\n",
    "        nn.BatchNorm2d(outplane),\n",
    "        nn.ReLU()    \n",
    "        )\n",
    "\n",
    "\n",
    "def conv_bw(inplane,outplane,kernel_size = 3,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,outplane,kernel_size = kernel_size,groups = 1,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(outplane),\n",
    "        nn.ReLU() \n",
    "        )\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_class=10):\n",
    "        super(MobileNet,self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "#         layers.append(conv_bw(3,32,3,1))\n",
    "        layers.append(conv_dw_server(32,64,1))\n",
    "        layers.append(conv_dw(64,128,2))\n",
    "        layers.append(conv_dw(128,128,1))\n",
    "        layers.append(conv_dw(128,256,2))\n",
    "        layers.append(conv_dw(256,256,1))\n",
    "        layers.append(conv_dw(256,512,2))\n",
    "\n",
    "        for i in range(5):\n",
    "            layers.append(conv_dw(512,512,1))\n",
    "        layers.append(conv_dw(512,1024,2))\n",
    "        layers.append(conv_dw(1024,1024,1))\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(1024,num_class)\n",
    "                )\n",
    "        self.feature = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.feature(x)\n",
    "        out = out.mean(3).mean(2)\n",
    "        out = out.view(-1,1024)\n",
    "        out = self.classifer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f180dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet(\n",
      "  (classifer): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      "  (feature): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mobilenet_server = MobileNet().to(device)\n",
    "print(mobilenet_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f9fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(mobilenet_server, (32, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca8104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov  1 14:23:31 2018\n",
    "@author: tshzzz\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_dw_client(inplane,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,inplane,kernel_size = 3,groups = inplane,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(inplane),\n",
    "        nn.ReLU()  \n",
    "        )\n",
    "\n",
    "def conv_bw(inplane,outplane,kernel_size = 3,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,outplane,kernel_size = kernel_size,groups = 1,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(outplane),\n",
    "        nn.ReLU() \n",
    "        )\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_class=10):\n",
    "        super(MobileNet,self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(conv_bw(3,32,3,1))\n",
    "        layers.append(conv_dw_client(32,1))\n",
    "#         layers.append(conv_dw(64,128,2))\n",
    "#         layers.append(conv_dw(128,128,1))\n",
    "#         layers.append(conv_dw(128,256,2))\n",
    "#         layers.append(conv_dw(256,256,1))\n",
    "#         layers.append(conv_dw(256,512,2))\n",
    "\n",
    "#         for i in range(5):\n",
    "#             layers.append(conv_dw(512,512,1))\n",
    "#         layers.append(conv_dw(512,1024,2))\n",
    "#         layers.append(conv_dw(1024,1024,1))\n",
    "\n",
    "#         self.classifer = nn.Sequential(\n",
    "#                 nn.Dropout(0.5),\n",
    "#                 nn.Linear(1024,num_class)\n",
    "#                 )\n",
    "        self.feature = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.feature(x)\n",
    "#         out = out.mean(3).mean(2)\n",
    "#         out = out.view(-1,1024)\n",
    "#         out = self.classifer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3051a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet(\n",
      "  (feature): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mobilenet_client = MobileNet().to(device)\n",
    "print(mobilenet_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cef09407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(mobilenet_client, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce31a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = optim.SGD(mobilenet_server.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "clientsoclist = []\n",
    "train_total_batch = []\n",
    "val_acc = []\n",
    "client_weights = copy.deepcopy(mobilenet_client.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d99f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(users)]\n",
    "client_receivesize_list = [[] for i in range(users)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a91e68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64731727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0.0.94\n"
     ]
    }
   ],
   "source": [
    "host = socket.gethostbyname(socket.gethostname())\n",
    "#host = 'localhost'\n",
    "port = 10080\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "285f7db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is listening on 10.0.0.94:10081\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "host = '10.0.0.94'  # Use your server's IP address\n",
    "port = 10081  # Replace with your desired port\n",
    "\n",
    "s = socket.socket()\n",
    "s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)  # Enable address reuse\n",
    "try:\n",
    "    s.bind((host, port))\n",
    "    s.listen(5)\n",
    "    print(f\"Server is listening on {host}:{port}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f36633ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conntected with ('10.0.0.53', 63917)\n"
     ]
    }
   ],
   "source": [
    "for i in range(users):\n",
    "    conn, addr = s.accept()\n",
    "    print('Conntected with', addr)\n",
    "    clientsoclist.append(conn)    # append client socket on list\n",
    "\n",
    "    datasize = send_msg(conn, epochs)    #send epoch\n",
    "    total_sendsize_list.append(datasize)\n",
    "    client_sendsize_list[i].append(datasize)\n",
    "\n",
    "    total_batch, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
    "    total_receivesize_list.append(datasize)\n",
    "    client_receivesize_list[i].append(datasize)\n",
    "\n",
    "    train_total_batch.append(total_batch)    # append on list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d19a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Client0 :   0%|                                                    | 0/4167 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmer start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Client0 : 100%|█████████████████████████████████████████| 4167/4167 [22:43<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train is done\n",
      "TrainingTime: 1373.587025642395 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    # store start time\n",
    "print(\"timmer start!\")\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # train client 0\n",
    "\n",
    "    for user in range(users):\n",
    "\n",
    "        datasize = send_msg(clientsoclist[user], client_weights)\n",
    "        total_sendsize_list.append(datasize)\n",
    "        client_sendsize_list[user].append(datasize)\n",
    "        train_sendsize_list.append(datasize)\n",
    "\n",
    "        for i in tqdm(range(train_total_batch[user]), ncols=100, desc='Epoch {} Client{} '.format(e+1, user)):\n",
    "            optimizer.zero_grad()  # initialize all gradients to zero\n",
    "\n",
    "            msg, datasize = recv_msg(clientsoclist[user])  # receive client message from socket\n",
    "            total_receivesize_list.append(datasize)\n",
    "            client_receivesize_list[user].append(datasize)\n",
    "            train_receivesize_list.append(datasize)\n",
    "\n",
    "            client_output_cpu = msg['client_output']  # client output tensor\n",
    "            label = msg['label']  # label\n",
    "\n",
    "            client_output = client_output_cpu.to(device)\n",
    "            label = label.clone().detach().long().to(device)\n",
    "\n",
    "            output = mobilenet_server(client_output)  # forward propagation\n",
    "            loss = criterion(output, label)  # calculates cross-entropy loss\n",
    "            loss.backward()  # backward propagation\n",
    "            msg = client_output_cpu.grad.clone().detach()\n",
    "\n",
    "            datasize = send_msg(clientsoclist[user], msg)\n",
    "            total_sendsize_list.append(datasize)\n",
    "            client_sendsize_list[user].append(datasize)\n",
    "            train_sendsize_list.append(datasize)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        client_weights, datasize = recv_msg(clientsoclist[user])\n",
    "        total_receivesize_list.append(datasize)         \n",
    "        client_receivesize_list[user].append(datasize)\n",
    "        train_receivesize_list.append(datasize)\n",
    "        \n",
    "print('train is done')\n",
    "\n",
    "end_time = time.time()  # store end time\n",
    "print(\"TrainingTime: {} sec\".format(end_time - start_time))\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './cifar10_sp_mobilenet_server.pth'\n",
    "torch.save(mobilenet_server.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8df3bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---total_sendsize_list---\n",
      "total_sendsize size: 2186219168 bytes\n",
      "number of total_send:  4169\n",
      "\n",
      "\n",
      "---total_receivesize_list---\n",
      "total receive sizes: 2187681835 bytes\n",
      "number of total receive:  4169\n",
      "\n",
      "\n",
      "---client_sendsize_list(user0)---\n",
      "total client_sendsizes(user0): 2186219168 bytes\n",
      "number of client_send(user0):  4169\n",
      "\n",
      "\n",
      "---client_receivesize_list(user0)---\n",
      "total client_receive sizes(user0): 2187681835 bytes\n",
      "number of client_send(user0):  4169\n",
      "\n",
      "\n",
      "---train_sendsize_list---\n",
      "total train_sendsizes: 2186219163 bytes\n",
      "number of train_send:  4168\n",
      "\n",
      "\n",
      "---train_receivesize_list---\n",
      "total train_receivesizes: 2187681820 bytes\n",
      "number of train_receive:  4168\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---total_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in total_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
    "print(\"number of total_send: \", len(total_sendsize_list))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in total_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
    "print(\"number of total receive: \", len(total_receivesize_list) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(users):\n",
    "    print('---client_sendsize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_sendsizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_sendsize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_receive sizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print(\"number of client_send(user{}): \".format(i), len(client_receivesize_list[i]))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_send: \", len(train_sendsize_list) )\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
    "print(\"number of train_receive: \", len(train_receivesize_list) )\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce3d5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/tejov/models/cifar10_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "731fb14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([32, 3, 32, 32])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 training dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Define DataLoader for the training set\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Now you can use train_loader in your code\n",
    "x_train, y_train = next(iter(train_loader))\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c84d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1563\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define your transformations (same as used for the train_loader)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define DataLoader for the test set\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Now you can use test_loader in your code\n",
    "train_total_batch = len(train_loader)\n",
    "print(train_total_batch)\n",
    "test_total_batch = len(test_loader)\n",
    "print(test_total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61638afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_client.load_state_dict(client_weights)\n",
    "mobilenet_client.to(device)\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './cifar10_sp_mobilenet_client.pth'\n",
    "torch.save(client_weights, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "928baf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 30.67%, train_loss: 1.9064\n"
     ]
    }
   ],
   "source": [
    "# train acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    train_loss = 0.0\n",
    "    for j, trn in enumerate(train_loader):\n",
    "        trn_x, trn_label = trn\n",
    "        trn_x = trn_x.to(device)\n",
    "        trn_label = trn_label.to(device)\n",
    "\n",
    "\n",
    "        trn_output = mobilenet_client(trn_x)\n",
    "        trn_label = trn_label.long()\n",
    "        \n",
    "        trn_output = mobilenet_server(trn_output)\n",
    "        \n",
    "        loss = criterion(trn_output, trn_label)\n",
    "        train_loss += loss.item()\n",
    "        model_label = trn_output.argmax(dim=1)\n",
    "        corr = trn_label[trn_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += trn_label.size(0)\n",
    "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(corr_num / total_num * 100, train_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d195e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 30.33%, test_loss: 1.9107\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.to(device)\n",
    "\n",
    "        val_output = mobilenet_client(val_x)\n",
    "        val_label = val_label.long()\n",
    "        \n",
    "        val_output = mobilenet_server(val_output)\n",
    "        \n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format(corr_num / total_num * 100, val_loss / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8908698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 39 %\n",
      "Accuracy of   car : 25 %\n",
      "Accuracy of  bird : 13 %\n",
      "Accuracy of   cat :  8 %\n",
      "Accuracy of  deer : 14 %\n",
      "Accuracy of   dog :  3 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 34 %\n",
      "Accuracy of truck : 63 %\n",
      "WorkingTime: 27.338175773620605 sec\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the classes for CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Assuming 'test_loader', 'mobilenet_client', and 'mobilenet_server' are already defined\n",
    "# Also assuming 'device' is defined, like 'cuda' or 'cpu'\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x, labels = data\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = mobilenet_client(x)\n",
    "        outputs = mobilenet_server(outputs)\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "end_time = time.time()  # Store end time\n",
    "print('WorkingTime: {} sec'.format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25917e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
